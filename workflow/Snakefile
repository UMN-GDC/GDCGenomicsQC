#report: "../report/main.rst"

configfile: "../config/config.yaml"
#validate(config, schema="../config/config.schema.yaml")

# Paths in include and configfile are relative to the Snakefile
# paths inside the rules are relative to where you run the command.

# CHROMOSOMES = range(1, 22)
CHROMOSOMES = range(20, 21)


# run single rule
# snakemake --cores 1 Initial_QC --config stage=01-Initialfilter
# snakemake --jobs 22 --configfile ../config/config2.yaml --cluster "sbatch --parsable" --use-singularity
# snakemake --jobs 22 --configfile ../config/config.yaml --cluster "sbatch --parsable"
import os 
PREVIOUS_STEP = {
    "01-Initialfilter": "00-raw",
    "02-relatedness": "01-Initialfilter",
    "03-localAncestry": "02-relatedness",
    "04-globalAncestry": "03-localAncestry",
}

def get_input_by_stage(wildcards):
    # Fix the typo 'wilcards' -> 'wildcards'
    if wildcards.stage == "01-Initialfilter":
        input_prefix = "data"
    else:
        input_prefix = "initial"

    # Ensure the stage exists in the map to avoid KeyErrors
    if wildcards.stage not in PREVIOUS_STEP:
        raise ValueError(f"Stage {wildcards.stage} not defined in PREVIOUS_STEP map.")

    prev = PREVIOUS_STEP[wildcards.stage]
    
    # Use os.path.abspath to make it bulletproof for SLURM
    path = os.path.join(config["OUT_DIR"], prev, input_prefix)
    return os.path.abspath(path)

# mount paths to external if using singularity
def get_mount_points(config_dict):
  """Recursively find all unique root directories from absolute paths in config."""
  paths = set()
  for value in config_dict.values():
      if isinstance(value, str) and value.startswith("/"):
          # Extract the root (e.g., /shared or /scratch)
          parts = value.split("/")
          if len(parts) > 1:
              paths.add(f"/{parts[1]}")
      elif isinstance(value, dict):
          paths.update(get_mount_points(value))
  return paths

if workflow.use_singularity:
    print("DEBUG: Singularity mode detected!")
    # 1. Start with the current project directory
    needed_binds = {os.getcwd()}
    
    # 2. Add all root directories found in the config
    needed_binds.update(get_mount_points(config))
    
    # 3. Format for Apptainer: --bind /shared:/shared,/scratch:/scratch
    bind_string = "--bind " + ",".join([f"{b}:{b}" for b in needed_binds])
    
    # 4. Inject into the workflow
    if workflow.singularity_args:
        workflow.singularity_args += f" {bind_string}"
    else:
        workflow.singularity_args = bind_string




include: "rules/LinkData.smk"
include: "rules/Initial_QC.smk"
include: "rules/Relatedness.smk"
include: "rules/Standard_QC.smk"
include: "rules/RFMIX.smk"
include: "rules/PCA.smk"
#include: "rules/plotInitial_QC.smk"

rule all:
    threads: 1
    resources:
        # nodes=1 is usually the default, but can be specified if needed
        nodes = 1,
        mem_mb = 4000,
        runtime = 420 # 1 week
    input:
        # Requesting this file triggers Initial_QC for the first stage
        os.path.join(config['OUT_DIR'], "00-raw/data.bed")
        #os.path.join(config['OUT_DIR'], "01-Initialfilter/initialFilter.bed")
        #os.path.join(config['OUT_DIR'], "02-relatedness/unrelated.bed")
        #os.path.join(config['OUT_DIR'], "02-relatedness/initialFilter.bed")
  #os.path.join(config['OUT_DIR'], "02-relatedness/standardFiltered.bed")
        #expand(f"{config['OUT_DIR']}/03-localAncestry/chr{{CHR}}.phased.vcf.gz", CHR=CHROMOSOMES),
        #os.path.join(config['OUT_DIR'], "04-globalAncestry/merged_dataset_pca.eigenvec")
        # imiss = os.path.join(config['OUT_DIR'], "figures/imiss.png"),
        #lmiss = os.path.join(config['OUT_DIR'], "figures/lmiss.png")
